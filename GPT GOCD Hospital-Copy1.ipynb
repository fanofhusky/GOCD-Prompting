{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cafcc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai;\n",
    "import time;\n",
    "import re;\n",
    "import requests;\n",
    "import os;\n",
    "import random;\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from dotenv import load_dotenv;\n",
    "import csv;\n",
    "import time;\n",
    "from openai import AzureOpenAI;\n",
    "\n",
    "# loading of environment variables, where the api keys should be stores\n",
    "load_dotenv();\n",
    "openai.api_type = \"azure\";\n",
    "openai.api_version = \"2023-05-15\" ;\n",
    "openai.api_base = os.getenv(\"ENDPOINT\");\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\");\n",
    "\n",
    "# object to store api keys\n",
    "client = AzureOpenAI(\n",
    "    api_key=openai.api_key,\n",
    "    api_version=openai.api_version,\n",
    "    azure_endpoint=openai.api_base,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516b3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in the api keys \"client\" and a prompt \"question\"\n",
    "# \"question\" needs to be in the form of template, which is defined below\n",
    "def query_store(client, question):\n",
    "    model_name = \"gpt-4-32k\";  \n",
    "    time_start = time.time();\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompt = f\"Q: {question} A:\";\n",
    "    \n",
    "    # Create a chat completion request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    );\n",
    "    \n",
    "    # Extract the content of the response\n",
    "    answer = response.choices[0].message.content;\n",
    "    time_elapsed = time.time() - time_start;\n",
    "\n",
    "    # Prepare a dictionary with the information\n",
    "    result = {\n",
    "        'model_name': model_name,\n",
    "        'runtime_seconds': time_elapsed,\n",
    "        'question': question,\n",
    "        'answer': answer\n",
    "    };\n",
    "    \n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db7409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template for our simulated hospital's patients\n",
    "# GENDER must be replaced with \"male\" or \"female\"\n",
    "# AGE must be replaced with a positive integer\n",
    "# CONDITION must be replaced with the condition name\n",
    "# X must be replaced with a positive integer\n",
    "# DID/DIDNOT must be replaced with \"did\" or \"did not\"\n",
    "# \"ADDENDUM\" is added if a GOCD did take place. Says which day the GOCD took place\n",
    "template = \"You are a medical scribe. There was a GENDER patient of age AGE who was hospitalized for CONDITION for X days. During their hospitalization, they DID/DIDNOT discuss their goals of care. For each day, detail their treatment and health status. ADDENDUMDo not explicitly mention \\\"goals of care\\\" in your summaries.\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560e9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes patient characteristics to generate a question following the template\n",
    "# each row has patient characteristics stored in the columns Sex, Cancer, Days, GOCD, and DayofGOCD\n",
    "def generate_question(row, template):\n",
    "    gender = \"male\" if row['Sex'] == 1 else \"female\";\n",
    "    age = row['Age'];\n",
    "    condition = \"Cancer\" if row['Cancer'] == 1 else \"Dementia\";\n",
    "    days = row['Days'];\n",
    "    did_or_didnot = \"did\" if row['GOCD'] == 1 else \"did not\";\n",
    "    addendum = f\"Explicitly detail the goals of care discussion, which took place on day {row['DayofGOCD']}. \" if row['GOCD'] == 1 else \"\";\n",
    "\n",
    "    summary = template.replace(\"GENDER\", gender) \\\n",
    "                      .replace(\"AGE\", str(age)) \\\n",
    "                      .replace(\"CONDITION\", condition) \\\n",
    "                      .replace(\"X\", str(days)) \\\n",
    "                      .replace(\"DID/DIDNOT\", did_or_didnot) \\\n",
    "                      .replace(\"ADDENDUM\", addendum)\n",
    "    \n",
    "    return summary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c390baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I take in a file with patient characteristics aligned in the format that generate_question takes\n",
    "file_path = r\"C:\\Users\\edber\\Desktop\\Road to PhD\\University of Washington\\PPI\\Palliative\\2024.08.21 patients.xlsx\";\n",
    "df = pd.read_excel(file_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f31dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model_name'] = \"\";\n",
    "df['runtime_seconds'] = 0.0;\n",
    "df['question'] = \"\";\n",
    "df['answer'] = \"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff808c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loop uses the patient in each row to generate a prompt based on the characteristics and then send that prompt to CHATGPT\n",
    "# after this step, df would be saved to an excel or csv and then sent to R for using PPI and DSL packages etc.\n",
    "for index, row in df.iterrows():\n",
    "    question = generate_question(row, template);\n",
    "    df.at[index, 'question'] = question;\n",
    "    query_result = query_store(client, question);\n",
    "    \n",
    "    df.at[index, 'model_name'] = query_result['model_name'];\n",
    "    df.at[index, 'runtime_seconds'] = query_result['runtime_seconds'];\n",
    "    df.at[index, 'question'] = query_result['question'];\n",
    "    df.at[index, 'answer'] = query_result['answer'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12b23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(r\"C:\\Users\\edber\\Desktop\\Road to PhD\\University of Washington\\PPI\\Palliative\\2024.08.21 narratives.xlsx\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
